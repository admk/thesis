\section{Performance Analysis}
\label{lo:sec:performance_analysis}

This section explains how we analyze \glspl{mir} for our three performance
metrics: latency, resource usage, and accuracy.

\subsection{Latency Analysis}
\label{lo:sub:latency}

The purpose of our latency analysis is not to create a complete scheduling
of numerical programs, as this would be computationally expensive, and would
need to be repeated for tens of thousands of equivalent programs.  Instead, it
computes a lower bound of the loop's \gls{ii}, the \acrfull{mii}.  (Recall that
the initiation interval is the number of clock cycles that must elapse between
the starts of two consecutive loop iterations, and is determined by data
dependences and resource constraints.)  We then compute the overall latency of
the loop, and subsequently, the total latency of the program.

Following LegUp~\cite{legup}, we compute \gls{mii} values using the first
few steps of modulo \gls{sdc} scheduling~\cite{canis14} introduced in depth
in Section~\ref{bg:sub:sdc} of Chapter~\ref{chp:background}, by viewing
\glspl{mir} as dependence graphs, as the structure of \glspl{mir} already
captures intra-iteration data-dependences.  In addition to this, we add extra
latency information as attributes on the edges of \glspl{mir}, plus new edges
to form cycles that capture inter-iteration data-dependences.  The analysis is
carried out in three stages.

The analysis starts with the \gls{mir} of the loop under analysis. Each edge
in the \gls{mir}, say $s\rightarrow t$, represents a data-dependence: the
operation at node $s$ must be evaluated fully before the operation at $t$
can begin.  The first step is to add a pair $\pair{l}{d}$ for each edge of
the \gls{mir}\@.  Here, $l$ is the \emph{latency} of the edge (the number of
\emph{clock cycles} that must elapse between the start of $s$ and the start
of $t$) and $d$ is the \emph{dependence distance} (the number of \emph{loop
iterations} that must elapse between the start of $s$ and the start of $t$).
Because all operations in the \gls{mir} are performed in a single iteration,
all edges have $d=0$.  The value of $l$ is given by the latency of the
operation at node $s$; if $s$ corresponds to an input variable or a numerical
constant, then $l=0$.

The second stage is to add edges to form a cyclic dependence graph that
captures \gls{raw} dependences across loop iterations.  This step involves
checking whether each pair of ``$\accessop$'' and ``$\updateop$'' nodes
has a dependence, and if so, adding a new edge between them with latency
and dependence distance attributes.  As an example, consider the \gls{mir}
in~\eqref{lo:eq:array_example} and assume each iteration increments \verb|i|
by 1.  Because in the original program, \verb|A[i]| and \verb|A[i+1]| are
respectively reading from and writing to the same array \verb|A|, we need to
check if these accesses could touch the same memory location in different
iterations.  For this, our analysis formulates an \gls{ilp} problem for
the dependence distance, and solves it using the \gls{isl}~\cite{isl}.
In this example, the dependence distance is 1 because the value written
to \verb|A[i+1]| in the current iteration \verb|i| is immediately used
in the next iteration \verb|i+1|.  Similarly, we also add new edges
for reads and writes to the same variable, which can be treated as a
special array with only one element. Our analysis yields the \gls{mir} in
Figure~\ref{lo:fig:example_latency}.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[mir, node distance=8mm, inner sep=0]
        \node[mirnode] (A) at (0,0) {\texttt{A}};
        \node[mirnode, inner sep=1.5mm] (update) [right=of A] {$\updateop$};
        \node[mirnode] (A1)    [below left=of update] {\texttt{A}};
        \node[mirnode] (plus)  [below=of update] {$+$};
        \node[mirnode] (i1)    [below left=of plus] {\texttt{i}};
        \node[mirnode] (n1)    [below right=of plus] {$1$};
        \node[mirnode] (times) [below right=of update, xshift=11mm] {$\times$};
        \node[mirnode] (n2)    [below left=of times] {$2$};
        \node[mirnode] (access)[below right=of times] {$\accessop$};
        \node[mirnode] (A2)    [below left=of access] {\texttt{A}};
        \node[mirnode] (i2)    [below right=of access] {\texttt{i}};

        \draw[|->] (A) -- (update);
        \draw[<-] (update) to[auto, swap, pos=0.8] node{\smallpair00} (A1);
        \draw[<-] (update) to[auto] node{\smallpair{10}0} (plus);
        \draw[<-] (update) to[auto] node{\smallpair70} (times);
        \draw[<-] (plus) to[auto, swap] node{\smallpair00} (i1);
        \draw[<-] (plus) to[auto] node{\smallpair00} (n1);
        \draw[<-] (times) to[auto, swap] node{\smallpair00} (n2);
        \draw[<-] (times) to[auto] node{\smallpair20} (access);
        \draw[<-] (access) to[auto, swap] node{\smallpair00} (A2);
        \draw[<-] (access) to[auto] node{\smallpair00} (i2);
        \brackets{(current bounding box)}
\begin{pgfinterruptboundingbox}
        \draw[<-,dashed] (access) to[auto, swap, pos=0.2, out=45, in=30]
        node{\smallpair{-2}1} (update);
\end{pgfinterruptboundingbox}
    \end{tikzpicture}
    \caption{%
        The \acrshort{mir} with edges labelled with latency attributes.
    }\label{lo:fig:example_latency}
\end{figure}

Note the new dashed edge from the $\updateop$ node to the $\accessop$ node,
which is labeled $\pair{-2}{1}$.  The first value, $-2$, signifies that the
latency of the edge between $\times$ and $\accessop$, which is 2 cycles, is
canceled out because the multiplier can reuse its output from the previous
iteration as the input for the current iteration. The second value, $1$,
indicates that there is a data flow dependence from iteration $i$ to iteration
$i+1$.

We assume no limit on the number of operators we can allocate, so operators
do not constraint \gls{ii}.  However, in \gls{vhls}, each array is usually
translated into a dual-port \gls{ram}, which allows only two accesses per
clock cycle~\cite{vivado_hls}, and thus constraints \gls{mii}.  Following
Section~\ref{bg:sub:sdc}, we evaluate:
\begin{equation}
    \ResMII = \max_{a\,\in\,A} \left\lceil \frac{n_a}{r_a} \right\rceil,
\end{equation}
where $a \in A$ ranges over all arrays in the loop body, $n_a$ is the number of
accesses to the array $a$, \ie~the number of shared $\accessop$ and $\updateop$
nodes accessing the array $a$ in the dependence graph, and $r_a = 2$ is the
maximum number of accesses allowed per cycle per array.

The final step is to calculate \acrfull{recmii} which is defined in
Section~\ref{bg:sub:sdc} as:
\begin{equation}
    \RecMII = \max_{c\,\in\,C} \left\lceil \frac{l_c}{d_c} \right\rceil,
\end{equation}
where $c \in C$ ranges over all cycles in the graph, and $l_c$ and $d_c$ are
respectively the sums of all latencies and dependence distances of the edges in
the cycle.  Because a typical \gls{mir} with array accesses could have a very
large number of cycles, we efficiently search for an \gls{mii} using a modified
Floyd--Warshall algorithm~\cite{floyd62}, following~\cite{rau94}.

Finally, we estimate the total latency $L$ of the loop with:
\begin{equation}
    L = (N - 1) \MII + D,
    \text{~where~}
        \MII = \max\left(\RecMII, \ResMII\right).
    \nonumber
\end{equation}
Recalling from Section~\ref{bg:sub:sdc} in Chapter~\ref{chp:background}, $N$ is
the maximum \emph{trip count}, \ie~the loop's total number of iterations, and
$D$ is the loop's depth, \ie~the total number of cycles per iteration.

Because we optimize \glspl{mir} in a bottom-up hierarchy, when an
expression that does not constitute a inter-iteration dependence is
optimized, its latency is estimated by scheduling its operations by using
an \gls{alap}~\cite{wang_hls} scheduling algorithm, where each operation
is scheduled to the latest opportunity, while respecting the order of data
dependences.

Because the expression is eventually used in a loop, and the \gls{ii} of
the loop is critical to how fast the loop can execute, it is necessary
to start optimizing for \gls{ii} as soon as possible.  Therefore, in our
latency analysis of a \gls{mir} or an expression that is a fragment of a
inter-iteration dependence cycle, our algorithm automatically shortens any
paths between any pairs of dependent accesses in the \gls{mir}\@, as we use the
latency analysis as a component to manoeuvre our optimization on the Pareto
frontier.  Moreover, we place greater weights on dependent accesses with
smaller dependence distances, because these impact the resulting loop \gls{ii}
more significantly than larger distances.  For instance, consider a loop body
that has two dependent accesses across iterations, \ie~the graph contains two
cycles:
\begin{lstlisting}
    A[i] = $f\left( \texttt{A[i-1]},\,\texttt{A[i-2]} \right)$;
\end{lstlisting}
Here as we optimize this program in a bottom-up hierarchy, $f$ is optimized
before the loop body.  For \gls{mii} considerations, the subexpression tree $f$
is thus rewritten such that the following latency cost is minimized:
\begin{equation}
    L = \max \left(
        \frac{l_1}{d_1}, \frac{l_2}{d_2}
    \right).
\end{equation}
Here, $l_1$ and $l_2$ are respectively the lengths
of the longest latency-weighted paths from the nodes
$\access{\texttt{A}}{\overline{\texttt{i}-1}}$ and
$\access{\texttt{A}}{\overline{\texttt{i}-2}}$ to the root of $f$, and $d_1$
and $d_2$ are respectively the dependence distances of the two nodes to the
write of \verb|A|, where $d_1 = 1$ and $d_2 = 2$.


\subsection{Resource Utilization Analysis}
\label{lo:sub:resource}

The hardware resource usage analysis of Chapter~\ref{chp:stropt} captures the
sharing of common subexpressions, but cannot analyze resource binding, which
allows common operations to be shared across clock cycles. For instance, in the
floating-point expression $\vara + (\varb + \varc)$, the two additions can be
computed using one addition operator only.  In this section, we develop a new
resource usage analysis that fully understands how resources are shared in an
\gls{fpga} implementation of numerical programs.

We rely on the foundation of resource usage analysis from
Chapters~\ref{chp:stropt} and~\ref{chp:progopt}, which counts the number
$n_\opsymbol$ of each type of operation $\opsymbol \in \opset$, while maximally
sharing common subexpressions.  In a pipelined loop, we compute a lower bound
$a_\opsymbol$ on the number of instances of $\opsymbol$ that must be allocated,
using the following formula:
\begin{equation}
    a_\opsymbol = \left\{
        \begin{aligned}
            & \left\lceil \frac{n_\opsymbol}{\MII} \right\rceil
            && \quad \text{if $\opsymbol$ is shared}, \\
            & \quad n_\opsymbol
            && \quad \text{otherwise}.
        \end{aligned}
    \right.
\end{equation}
Here, integer operators are typically not shared~\cite{cong15}, so the number
of operations is the number of allocated instances.

For instance, if we know that a pipelined loop has $\MII = 3$, and each
iteration uses 6 multiplications, then we can compute that we need to
synthesize at least 2 multipliers.

For straight-line code, non-pipelined loops, and different loops, we use a
simple \gls{alap} scheduling~\cite{wang_hls} to estimate resource utilization.

Finally, we accumulate the number of \glspl{lut} and \gls{dsp} elements
for all allocated operators.  In addition, we estimate the number of
\glspl{lut} required by multiplexers generated for sharing operators, where
$R^\mathrm{LUTs}_\mathrm{mux}$ approximates $1/n$ of the number of \glspl{lut}
required by an $n$-to-1 multiplexer.  The final result is the estimated
resource utilization for the full program:
\begin{equation}
    \begin{aligned}
        r_\mathrm{LUT} &=
            \sum_{\opsymbol \in \opset} \left(
                a_\opsymbol R^\mathrm{LUTs}_\opsymbol +
                \left( n_\opsymbol - a_\opsymbol \right)
                    R^\mathrm{LUTs}_\mathrm{mux}
            \right), \\
        r_\mathrm{DSP} &=
            \sum_{\opsymbol \in \opset} a_\opsymbol R^\mathrm{DSPs}_\opsymbol,
    \end{aligned}
\end{equation}
where $R^\mathrm{LUTs}_\opsymbol$ and $R^\mathrm{DSPs}_\opsymbol$ denote the
number of \glspl{lut} and \glspl{dsp} required by one operator $\opsymbol$
respectively.


\subsection{Accuracy Analysis}
\label{lo:sub:accuracy}

We extend the accuracy analysis of Chapter~\ref{chp:progopt} to support arrays.
Because our benchmark suite consists of programs with large arrays, we keep
the analysis efficient by treating an \emph{entire} array as a pair of a
floating-point interval and an interval of accumulated round-off errors.  These
intervals accumulate all values that are assigned to the array, and never
shrink the range bounded by these intervals when we assign new values to an
array location.  We therefore define the read and write accesses to an array as
follows in the accuracy analysis:
\begin{equation}
    \begin{aligned}
        \exprerrorfunc{\access{A}{\bar\imath}}\sigma^\sharp
        &= \exprerrorfunc{A}\sigma^\sharp, \\
        \exprerrorfunc{\update{A}{\bar\imath}{e}}\sigma^\sharp
        &= \exprerrorfunc{A}\sigma^\sharp \sqcup
           \exprerrorfunc{e}\sigma^\sharp,
    \end{aligned}
\end{equation}
where $A \in \varset$ is an array variable, $\bar\imath$ is a subscript
to index an element in $A$, $e \in \sexprset$ is an expression, and
$\sigma^\sharp \in \errordom$ is the input abstract program state (recall from
Section~\ref{po:sec:accuracy_analysis} of Chapter~\ref{chp:progopt}).

Alternatively, we can view each element $A[i]$, where $i$ is a tuple with $N$
non-negative integers, in an $N$-dimensional array $A$ as a variable.  Updating
$A$ thus produces an abstract state which collects all elements in $A$:
\begin{equation}
    \begin{aligned}
        \exprerrorfunc{\access{A}{\bar\imath}}\sigma^\sharp
        &= \bigsqcup_{i \in \exprerrorfunc{\bar\imath}\sigma^\sharp}
            \sigma^\sharp \left( A[i] \right), \\
        \exprerrorfunc{\update{A}{\bar\imath}{e}}\sigma^\sharp
        &= {\left[
            A[i] \mapsto \sigma^\sharp \left( A[i] \right) \sqcup
                \exprerrorfunc{e}\sigma^\sharp
        \right]}_{i \in \exprerrorfunc{\bar\imath}\sigma^\sharp},
    \end{aligned}
\end{equation}
where $i \in \exprerrorfunc{\bar\imath}\sigma^\sharp$ ranges over all possible
indices that are tuples with $N$ non-negative integers, where $A$ is an
$N$-dimensional array.

Additionally, because most of the loops in our benchmark programs consist
of nested loops and have large iterations, the fixpoint analysis routine
in Section~\ref{po:sub:fixpoint} is modified to analyze only a small
fraction of the innermost loop execution of a loop nest.  By ensuring the
innermost loop iterator increments by the same amount, we can guarantee the
accuracy analysis to be fair for each equivalent implementation for fixpoint
expressions with different unroll factors.  For the experimental outcomes in
Section~\ref{lo:sec:results}, we analyze $10\%$ of the total executions of an
innermost loop for the purpose of optimization.

Finally, we further use the dependence analysis in the \gls{mir} graph
explained in Section~\ref{lo:sub:latency} to detect whether errors are
accumulated across iterations.  This process is carried out by first analyzing
the \gls{mir} of the loop body for intra-iteration dependences.  The absence
of such dependences indicates the round-off errors do not accumulate across
iterations, and it suffices to analyze the fixpoint expression for one loop
iteration.
