\section{Introduction}
\label{po:sec:introduction}

The previous chapter introduced a new methodology to efficiently restructure
arithmetic expressions for the optimized trade-off between two performance
metrics, \ie~numerical accuracy when evaluated and area usage in synthesized
\gls{fpga} implementations.  This method however has a substantial limitation
when applied to general numerical programs, that is, it can only be applied to
straight-line codes without control structures such as branches and loops.

In this chapter, a new general \emph{program} optimization technique for
numerical algorithms is therefore proposed, which analyzes and optimizes
\texttt{if} statements as well as \texttt{while} loops in a numerical program.
This enables the joint optimization of accuracy and resource usage, as well
as the trade-off between both performance metrics.  A tool is thus developed
to perform source-to-source optimization of numerical programs targeting
\glspl{fpga}, and generate implementations that trade off resource usage and
numerical accuracy.

% floating-point arithmetic has round-off errors, exploit equivalence

Similar to the approach proposed in Chapter~\ref{chp:stropt}, equivalence rules
such as such as \emph{associativity} $(a + b) + c \equiv a + (b + c)$, and
\emph{distributivity} $(a + b) \times c \equiv a \times c + b \times c$ are
exploited to automatically optimize implementations for the optimal trade-off
between resource usage, \ie~the number of \glspl{lut} and \gls{dsp} elements
utilized, and accuracy when evaluated using floating-point computations.  This
process generates a Pareto frontier of optimized numerical programs.  For
example, with single-precision floating-point format, the tool finds that given
an input $x \in [0, 100]$ and $y \in [0, 2]$, then the program:
\begin{lstlisting}
    if (x < 1) {
        x = (x + y) + 0.1;
    } else {
        x = x + (y + 0.1);
    }
\end{lstlisting}
is most accurate when the subexpression \verb|(x + y) + 0.1| is rewritten
as \verb|(x + 0.1) + y|; on the other hand, the original program uses
fewest resources when subexpressions are shared and the \iflit~statement is
eliminated:
\begin{lstlisting}
    x = x + (y + 0.1);
\end{lstlisting}

The structural optimization of general numerical programs is much more complex
than that of arithmetic expressions.  The reasons are three-fold.  First,
during program execution, variables are often updated with new values.  Our
optimization should therefore perform static analysis on the values of
variables, and use the result to optimize specifically for the trade-off
between accuracy and resource usage.  Second, the combinatorial explosion of
expression equivalence, is further exacerbated by the expressiveness of a
general numerical program.  Finally, it is much more difficult to formally
define program equivalence, and subsequently, to search efficiently for
optimized equivalent programs.

The difficulty in defining program equivalence is due to the fact that two
programs can be identical in function, but have distinct syntactic structure
because of the expressiveness of a \gls{hll}\@.  For instance, even without
the introduction of branches and loops, the following two C programs in
Figure~\ref{bg:fig:equiv_progs} are equivalent, but syntactically, they are
very different.
\begin{figure}[ht]
    \centering
    \subfloat[$P_1$]{%
        \shortstack[l]{%
            \texttt{x = x + 1;} \\
            \texttt{y = 2 * x;} \\
            \texttt{x = x + 3;}
        }
    } \qquad \qquad
    \subfloat[$P_2$]{%
        \shortstack[l]{%
            \texttt{y = x + 1;} \\
            \texttt{x = y;} \\
            \texttt{y = y * 2;} \\
            \texttt{x = x + 3;}
        }
    }
    \caption{%
        Two programs that are equivalent but syntactically different.
    }\label{bg:fig:equiv_progs}
\end{figure}

In fact, one can easily imagine infinitely many ways to rewrite numerical
programs, and often these equivalent programs have identical resource usage,
latency and accuracy characteristics.  In practice, it is desirable to
eliminate as much as possible the need for these syntactic rewrites that do not
affect our performance metrics, so that the search space of equivalent programs
is greatly reduced.

We explored in Section~\ref{bg:sec:intermediate} of
Chapter~\ref{chp:background} various \acrfullpl{ir} designed for program
transformation, and specifically examined \acrfull{peg} in closer details,
because it fits our requirement to abstract away as much irrelevant syntactic
information as possible.  However, \gls{peg} is not suited for the optimization
of numerical accuracy because cycles in graphs are used.  Evaluating the
numerical accuracy of an \gls{ir} with a cyclic structure require analyzing
a large proportion of the \gls{ir}, whereas a tree structure can be reasoned
compositionally in a bottom-up hierarchy.  By introducing equivalence edges
in the graph, the number of elementary cycles in the graph could increase
exponentially in the number of equivalences that have been discovered,
which further exacerbates the already high computational demand.  This has
significant implications for program transformation.  First, for the above
reason, their approach does not use static analysis to optimize for numerical
accuracy, while we wish to reason about accuracy and utilize them to steer
optimization.  Moreover, the tree structure allows us to easily support partial
loop unrolling by simply extending the equivalence relations while avoiding
re-evaluation.  In contrast, like~\cite{martel09} and~\cite{damouche15},
equality saturation is unable to perform partial loop unrolling.  In this
chapter, a solution to the above limitations of \glspl{peg} is therefore
proposed, by introducing a new tree-based \gls{ir} with fixpoint constructs to
specifically tackle the problem of program equivalences.

Additionally, as none of the methods in
Section~\ref{bg:sec:discovering_equivalent_programs} of
Chapter~\ref{chp:background} looks at the multiple-objective optimization of
numerical programs, this chapter is the first to propose a tool that performs a
semantics-directed program transformation, which optimizes not only arithmetic
expressions, but also numerical programs.  The tool optimizes for the trade-off
between numerical accuracy and resource usage when synthesized to \glspl{fpga}.

The optimization flow is designed to be \emph{flexible}, and its implications
are three-fold.  Firstly, arithmetic computations can be optimized across
assignments, \iflit~statements and \whilelit~loops.  Secondly, we automatically
explore the numerical implications of partial loop unrolling and loop
splitting, which can create more opportunity for minimizing round-off errors,
hence further increases range of options in the Pareto frontier of trade-offs.
Finally, our method naturally subsumes constant propagation, redundant code
elimination, and also branch and loop fusions.

The main contributions in this chapter are as follows:
\begin{enumerate}

    \item \acrfull{mir}, A new \gls{ir} of the behaviour of numerical programs.
    Its structure is designed to be manipulated and analyzed with ease.

    \item Semantics-based analyses that reason about not only the resource
    utilization (number of \glspl{lut} and \gls{dsp} elements), and safe ranges
    of values and errors for programs, but also potential errors such as
    overflows and non-termination.  This provides the cost functions that we
    wish to minimize by rewriting programs.

    \item A new framework of numerical program transformations is
    developed based on the methods in Section~\ref{so:sec:equivalent} of
    Chapter~\ref{chp:stropt}.  It enables the back and forth translation
    between the program and \gls{mir}, which preserves the semantics of the
    original program in real arithmetic.

    \item The updated tool, \soap, which trades off resource usage and accuracy
    by providing a safe, semantics-directed and flexible optimization targeting
    numerical programs for high-level synthesis.  Experimental results are
    presented in Section~\ref{po:sec:results}.

\end{enumerate}

This chapter is organized as follows.  We start by defining our program
syntax in Section~\ref{po:sec:syntax_definition}.  Using the syntax
definition, this section gives a detailed formal explanation of the
numerical program transformation, which consists of three stages.
Sections~\ref{po:sec:program_to_mir} describe how how numerical programs can
be translated into \glspl{mir}.  Sections~\ref{po:sec:accuracy_analysis}
and~\ref{po:sec:resource} respectively discuss how we infer bounds
and error bounds on variables and analyze resource usage estimates.
Section~\ref{po:sec:equivalence_analysis} explains how these analyses can
be used to efficiently discover equivalent structures in the analyzed
\gls{mir}\@.  Section~\ref{po:sec:code_generation} explains how a chosen
\gls{mir} can be translated into an optimized numerical program.  Then we
present the optimization results in Section~\ref{po:sec:results} and finally
Section~\ref{po:sec:conclusion} concludes this chapter.
