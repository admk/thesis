\section{Novel Semantics}
\label{so:sec:semantics}

\subsection{Accuracy Analysis}

In Section~\ref{bg:sub:accuracy} of Chapter~\ref{chp:background}, we described
a technique to analyze the round-off error of evaluating an expression tree.
Throughout this chapter, we use the function $\error: \exprset\to\errorset$ to
represent the above-mentioned analysis of evaluation accuracy, where $\exprset$
denotes the set of all expressions.


\subsection{Resource Usage Analysis}

Here we define similar formal semantics which calculate an approximation to the
FPGA resource usage of an expression, taking into account common subexpression
elimination. This is important as, for example, rewriting $a \times b + a
\times c$ as $a \times (b + c)$ in the larger expression $(a \times b + a
\times c) + {(a \times b)}^2$ causes the common subexpression $a \times b$ to
be no longer present in both terms. Our analysis must capture this.

The analysis proceeds by labelling subexpressions. Intuitively, the set of
labels $\labelset$, is used to assign unique labels to unique expressions,
so it is possible to easily identify and reuse them. For convenience, let
the function $\fresh: \exprset\to\labelset$ assign a distinct label to each
expression or variable, where $\exprset$ is the set of all expressions. Before
we introduce the labeling semantics, we define the environment $\lambda:
\labelset\to\exprset\cup\{\bot\}$, which is a function that maps labels to
expressions, and $\env{}$ denotes the set of such environments. A label $l$ in
the domain of $\lambda\in\env{}$ that maps to $\bot$ indicates that $l$ does
not map to an expression. An element $(l, \lambda)\in\labelset\times\env{}$
stands for the labeling scheme of an expression. Initially, we map all labels
to $\bot$, then in the mapping $\lambda$, each leaf of an expression is
assigned a unique label, and the unique label $l$ is used to identify the leaf.
That is for the leaf variable or constant $x$:
\begin{equation}
    (l, \lambda) = (\fresh(x), [\fresh(x)\mapsto{x}])
\end{equation}
This equation uses $[\fresh(x)\mapsto{x}]$ to indicate an environment that
maps the label $\fresh(x)$ to the expression $x$ and all other labels map
to $\bot$, in other words, if $l = \fresh(x)$ and $l^\prime \neq l$, then
$\lambda(l) = x$ and $\lambda(l^\prime) = \bot$.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.6]{sample_tree}
    \caption{The DFG for the sample expression.}\label{so:fig:sample_tree}
\end{figure}
For example, for the DFG in Figure~\ref{so:fig:sample_tree}, taken from
Section~\ref{bg:sec:abstract_interpretation} of Chapter~\ref{chp:background},
we have for the variables $a$ and $b$:
\begin{equation}
    \begin{aligned}
        (l_a, \lambda_a) &= (\fresh(a), [\fresh(a)\mapsto{a}])
                   = (l_1, [l_1 \mapsto a]) \\
        (l_b, \lambda_b) &= (l_2, [l_2 \mapsto b])
    \end{aligned}
    \label{so:eq:variable_env}
\end{equation}
Then the environments are propagated in the flow direction of the DFG, using
the following formulation of the labeling semantics:
\begin{equation}
    \begin{aligned}
        (l_x, \lambda_x) \circ (l_y, \lambda_y)
            &= (l, (\lambda_x\odot\lambda_y)
                      [l\mapsto{l_x \circ l_y}]) \\
            \text{where~} l &= \fresh(l_x \circ l_y),
                          \circ\in\{+, -, \times\}
    \end{aligned}
    \label{so:eq:labeling_semantics}
\end{equation}
Specifically, $\lambda=\lambda_x\odot\lambda_y$ signifies that $\lambda_y$
is used to update the mapping in $\lambda_x$, if the mapping does not
exist in $\lambda_x$, and result in a new environment $\lambda$; and
$\lambda[l\mapsto{x}]$ is a shorthand for $\lambda\odot[l\mapsto{x}]$.  As
an example, with the expression in Figure~\ref{so:fig:sample_tree}, using
\eqref{so:eq:variable_env}, recall to mind that $l_1 = l_a$, $l_2 = l_b$, we
derive for the subexpression $a + b$:
\begin{equation}
    \begin{aligned}
        (l_{a + b}, \lambda_{a + b})
            &= (l_a, \lambda_a) + (l_b, \lambda_b) \\
            &= (l_3, (\lambda_a \odot \lambda_b) [l_3\mapsto{l_a + l_b}]) \\
            &  \text{where~} l_3 = \fresh(l_a + l_b) \\
            &= (l_3, [l_1\mapsto{a}]\odot
                     [l_2\mapsto{b}]\odot
                     [l_3\mapsto{l_1 + l_2}]) \\
            &= (l_3, [l_1\mapsto{a}, l_2\mapsto{b}, l_3\mapsto{l_1 + l_2}])
    \end{aligned}
\end{equation}
\todo{George: I am a little confused by addition here.  What is the definition
of ``+'' on labels?  If $l_a + l_b$ should be read purely as a syntactic
construct, why does it need a distinct representation as $l_3$?}
Finally, for the full expression $(a + b) \times (a + b)$:
\begin{equation}
    \begin{aligned}
        (l, \lambda)
            &= (l_{a + b}, \lambda_{a + b}) \times
               (l_{a + b}, \lambda_{a + b}) \\
            &= (l_4, [l_1\mapsto{a}, l_2\mapsto{b},
                      l_3\mapsto{l_1 + l_2}, l_4\mapsto{l_3 \times l_3}])
    \end{aligned}
\end{equation}
From the above derivation, it is clear that the semantics capture the reuse
of subexpressions. The estimation of area is performed by counting, for an
expression, the numbers of additions, subtractions and multiplications in
the final labeling environment, then calculating the number of LUTs used to
synthesize the expression. If the number of operators is $n_\circ$ where
$\circ\in\{+,-,\times\}$, then the number of LUTs in total for the expressions
is estimated as $\sum_{\circ\in\{+,-,\times\}} A_\circ n_\circ$, where the
value $A_\circ$ denotes the number of LUTs per $\circ$ operator, which is
dependent on the type of the operator and the floating-point format used to
generate the operator.

In the following sections, we use the function $\area: \exprset\to\naturalset$
to denote our resource usage analysis.

\subsection{Equivalent Expressions Analysis}
\label{so:sub:equivalent_expressions_analysis}

In earlier sections, we introduce semantics that define additions and
multiplications on intervals, then gradually transition to error semantics that
compute bounds of values and errors, as well as labelling environments that
allow common subexpression elimination, by defining arithmetic operations on
these structures. In this section, we now take the leap from not only analyzing
an expression for its quality, to defining arithmetic operations on sets of
equivalent expressions, and use these rules to discover equivalent expressions.
Before this, it is necessary to formally define equivalent expressions and
functions to discover them.

\subsubsection{Discovering Equivalent Expressions}

From an expression, a set of equivalent expressions can be discovered by our
\emph{equivalence relation} $\eqrel$ on the set of all expressions $\exprset$,
and $\eqrel \subset \exprset\times\exprset$.  It is noteworthy that a relation
is said to be an equivalence relation when it is reflexive, symmetric and
transitive, \ie~for all $e_1, e_2, e_3 \in \exprset$, we have the following
rules in our inference system:
\begin{equation}
    \begin{aligned}
        \text{Reflexivity}
            &: e_1 \eqrel e_1 \\
        \text{Symmetry}
            &: \text{~if~} e_1 \eqrel e_2,
            \text{~then~} e_2 \eqrel e_1 \\
        \text{Transitivity}
            &: \text{~if~} e_1 \eqrel e_2 \text{~and~} e_2 \eqrel e_3,
            \text{~then~} e_1 \eqrel e_3.
    \end{aligned}
    \label{so:eq:equivalence_relation}
\end{equation}

We extend our inference system with additional rules that relate equivalent
expressions.  Let's define $e_1, e_2, e_3 \in \exprset$, $v_1, v_2, v_3 \in
\realset$, and $\circ \in \{+, \times\}$.  First, the arithmetic rules are:
\begin{equation}
    \begin{aligned}
        \text{Associativity}(\circ)
            &: (e_1 \circ e_2) \circ e_3 \eqrel e_1 \circ (e_2 \circ e_3) \\
        \text{Commutativity}(\circ)
            &: e_1 \circ e_2 \eqrel e_2 \circ e_1 \\
        \text{Distributivity}
            &: e_1 \times (e_2 + e_3) \eqrel e_1 \times e_2 + e_1 \times e_3
    \end{aligned}
    \label{so:eq:equivalence_arithmetic}
\end{equation}
Secondly, the reduction rules are:
\begin{equation}
    \begin{aligned}
        \text{Identity}(\times)
            &: e_1 \times 1 \eqrel e_1 \quad &
        \text{Zero Propagation}
            &: e_1 \times 0 \eqrel 0 \\
        \text{Identity}(+)
            &: e_1 + 0 \eqrel e_1 &
        \text{Constant Propagation}(\circ)
            &: \inference{v_3 = v_1 \circ v_2}{v_1 \circ v_2 \eqrel v_3}
    \end{aligned}
    \label{so:eq:equivalence_reduction}
\end{equation}
The Constant Propagation rule states that if an expression is a
summation/multiplication of two values, then it can be simply evaluated to
produce the result. Finally, the following two allow structural induction on
expression trees, \eg~it is possible to derive that $a + (b + c) \eqrel a + (c
+ b)$ from $b + c \eqrel c + b$:
\begin{equation}
    \begin{aligned}
        \text{Tree}(\circ)
            : \inference{e_1 \eqrel e_2}{e_3 \circ e_1 \eqrel e_3 \circ e_2}
        \quad &
        \text{Tree}^\prime(\circ)
            : \inference{e_1 \eqrel e_2}{e_1 \circ e_3 \eqrel e_2 \circ e_3}
    \end{aligned}
    \label{so:eq:equivalence_tree}
\end{equation}

We say that $e_1$ is equivalent to $e_2$ if and only if $e_1 \eqrel e_2$ For
some expressions $e_1$ and $e_2$.  Although for simplicity, we have not defined
rules for subtraction and division, these rules can be easily added and are
present in our framework.


\subsubsection{Scalable Methods}

The above rules of equivalence relates an expression with all of its equivalent
expressions.  In general because of combinatorial explosion, the set of all
equivalent expressions is so large to be derived, which motivates us to develop
scalable methods that execute fast enough even with large expressions.

Instead of deriving the full set of equivalent expressions, we can define
a new relation $\eqgenrel$, a subset of $\eqrel$, which is identical to
our equivalent relation $\eqrel$ except that we do not have transitivity
in~\eqref{so:eq:equivalence_relation} from $\eqrel$, to generate equivalent
expressions in a series of steps.

We define the function $\eqstep: \powersetof\exprset\to\powersetof\exprset$,
where $\powersetof\exprset$ denotes the power set of $\exprset$, which
generates a (possibly larger) set of equivalent expressions from an initial set
of equivalent expressions by one step of $\eqgenrel$, that is:
\begin{equation}
    \eqstep(\epsilon) = \left\{
        e^\prime\in\exprset \mid
        e \eqgenrel e^\prime \wedge e\in\epsilon\right\}
    \label{so:eq:eqstep}
\end{equation}
where $\epsilon$ is a set of equivalent expressions.
\begin{corollary}
    By the definition of $\eqstep$ in~\eqref{so:eq:eqstep}, $\eqstep(\epsilon_a
    \cup \epsilon_b) = \eqstep(\epsilon_a) \cup \eqstep(\epsilon_b)$.
    \label{so:cor:union}
\end{corollary}

From this, we may note that we can define a function
$\eqstep^{\star:N}(\epsilon)$ to generate a set of equivalent expressions,
by taking the union of $N$ steps of $\eqstep$ of $\epsilon$, as given by the
following formula:
\begin{equation}
    \eqstep^{\star:N}(\epsilon) = \bigcup_{i = 0}^N \eqstep^i(\epsilon)
    \label{so:eq:transitive_generator}
\end{equation}
Here we define:
\begin{equation}
    \begin{aligned}
        \eqstep^0(\epsilon) &= \epsilon \quad \text{and~} \\
        \eqstep^i(\epsilon) &= \eqstep\left(
            \eqstep^{i - 1}\left(\epsilon\right)
        \right) \quad \text{for~} i \in \{ 0, 1, 2, \cdots \}
    \end{aligned}
\end{equation}
By allowing $N$ to approach $\infty$, we obtain the full set of equivalent
expressions of $\epsilon$, \ie~the transitive closure:
\begin{equation}
    \eqstep^\star(\epsilon)
    = \eqstep^{\star:\infty}(\epsilon)
    = \bigcup_{i = 0}^\infty \eqstep^i(\epsilon)
    \label{so:eq:transitive_closure}
\end{equation}

\begin{lemma}
    $\eqstep^{\star:N}(\epsilon) = \epsilon \cup
    \eqstep\left(\eqstep^{\star:N-1}(\epsilon)\right)$.
    \label{so:lem:transitive}
\end{lemma}
\begin{proof}
    Following~\eqref{so:eq:transitive_generator}, $\eqstep^{\star:N}(\epsilon)
    = \eqstep^0(\epsilon) \cup \eqstep^1(\epsilon) \cup \cdots \cup
    \eqstep^N(\epsilon)$.  We then apply Corollary~\eqref{so:cor:union} to the
    right-hand side to get $\epsilon \cup \eqstep\left( \eqstep^0(\epsilon)
    \cup \eqstep^1(\epsilon) \cup \cdots \cup \eqstep^{N-1}(\epsilon)\right)$,
    which equals to $\epsilon \cup \eqstep\left( \eqstep^{\star:N-1}(\epsilon)
    \right)$ by definition.
\end{proof}

In practice, it is often infeasible to generate the full transitive closure of
a given expression, we therefore impose further constraints on how we discover
equivalent expressions.

First, instead of exploring the full transitive closure, that is, by allowing
the number of steps $N$ in~\eqref{so:eq:transitive_generator} to be infinite,
we may restrict $N$ to be a small finite value to allow a smaller set of
equivalent expressions to be computed.

Second, the complexity of equivalent expression finding is reduced by fixing
the structure of subexpressions at a certain depth $k$ in the original
expression.  The definition of depth is given as follows: first the root
of the parse tree of an expression is assigned depth $d = 1$; then we
recursively define the depth of a node as one more than the depth of its
greatest-depth parent.  If the depth of the node is greater than $k$, then
we fix the structure of its child nodes by disallowing any equivalence
transformation beyond this node. We let $\eqstep_k$ denote this ``depth
limited'' equivalence finding function, where $k$ is the depth limit used.  We
use $\eqstep^{\star:N}_k$ and $\eqstep^\star_k$ to denote the functions to
respectively compute the union of $N$ steps of $\eqstep_k$ and the transitive
closure. This approach is similar to Martel's depth limited equivalent
expression transform~\cite{martel07}, however Martel's method eventually allows
transformation of subexpressions beyond the depth limit, because rules of
equivalence would transform these to have a smaller depth.  This contributes
to a time complexity at least exponential in terms of the expression size. In
contrast, our technique has a time complexity that does not depend on the size
of the input expression, but grows with respect to the depth limit $k$. Note
that the full equivalence closure using the inference system we defined earlier
in~\eqref{so:eq:transitive_closure} is at least $O({2n - 1}!!)$ where $n$ is
the number of terms in an expression, as we discussed earlier.

Finally, we use the iterative algorithm in Figure~\ref{so:alg:eqstep} to
efficiently compute $\eqstep^{\star:N}_k$.  In each iteration, we keep track of
the equivalent expressions that are newly discovered in the current iteration,
so that in the next iteration we apply $\eqgenrel$ only to those expressions,
to avoid redundant computation.  We then continue to prove that this algorithm
indeed computes $\eqstep^{\star:N}_k$.
\begin{figure}[ht]
    \centering
    \begin{algorithmic}
        \Function{Equivalent}{$\epsilon$, $k$, $N$}
            \State{$s_0 \gets \epsilon$}
            \State{$s^\prime_0 \gets \epsilon$}
            \For{$i \gets 1, \ldots, N$}
                \State{$s^\prime_i \gets
                    \eqstep_k \left(s^\prime_{i-1}\right) - s_{i-1}$}
                \State{$s_i \gets s_{i-1} \cup s^\prime_i$}
                \If{$s^\prime_i \neq \emptyset$}
                    \State{\Return{$s_i$}}
                \EndIf{}
            \EndFor{}
            \State{\Return{$s_i$}}
        \EndFunction{}
    \end{algorithmic}
    \caption{%
        Our algorithm to discover a set of equivalent expressions from an
        initial set $\epsilon$.
    }\label{so:alg:eqstep}
\end{figure}
\begin{theorem}
    In the algorithm in Figure~\ref{so:alg:eqstep}, at iteration
    $n$, the set of equivalent expressions $s_n$ computes exactly
    $\eqstep^{\star:n}_k(\epsilon)$.
\end{theorem}
\begin{proof}
    We start by assuming that at iteration $m > 0$, $s_m =
    \eqstep^{\star:m}_k(\epsilon)$, and we prove this equality still holds if
    substitute $m$ with $m + 1$.  From the algorithm, we can deduce:
    \begin{equation*}
    \begin{aligned}
        s_{m+1}
         &= s_m \cup s^\prime_{m+1} \\
         &= s_m \cup \left( \eqstep_k \left( s^\prime_m \right) - s_m \right) \\
         &= s_m \cup \eqstep_k \left( s^\prime_m \right) \\
         &= s_m \cup \eqstep_k \left(
                \eqstep_k \left( s^\prime_{m-1} \right) - s_{m-1}
            \right)
    \end{aligned}
    \end{equation*}
    We substitute $s_m$ using Lemma~\ref{so:lem:transitive} to get:
    \begin{equation*}
        s_{m+1}
          = \epsilon \cup \eqstep_k \left( s_{m-1} \right) \cup
            \eqstep_k \left(
                \eqstep_k \left( s^\prime_{m-1} \right) - s_{m-1}
            \right)
    \end{equation*}
    Using distributivity of $\eqstep_k$ over $\cup$ and the iteration $m$ of
    the algorithm, we can derive:
    \begin{equation*}
    \begin{aligned}
        s_{m+1}
         &= \epsilon \cup \eqstep_k \left(
                s_{m-1} \cup \left(
                    \eqstep_k \left( s^\prime_{m-1} \right) - s_{m-1}
                \right)
            \right) \\
         &= \epsilon \cup \eqstep_k \left( s_m \right)
    \end{aligned}
    \end{equation*}
    Finally, we make use of the assumption $s_m =
    \eqstep^{\star:m}_k(\epsilon)$, followed by Lemma~\ref{so:lem:transitive}
    to show:
    \begin{equation*}
        s_{m+1}
        = \epsilon \cup \eqstep_k \left(
            \eqstep^{\star:m}_k(\epsilon)
        \right)
        = \eqstep^{\star:m+1}_k(\epsilon)
    \end{equation*}
    It is trivial that $s_0 = \epsilon = \eqstep^{\star:0}_k(\epsilon)$, by
    induction, $s_n = \eqstep^{\star:n}_k(\epsilon)$ thus holds for all $n \in
    \naturalset$.
\end{proof}

\subsubsection{Pareto Frontier}

Because we optimize expressions in two quality metrics, \ie~the accuracy of
computation and the estimate of FPGA resource utilization, there is a trade-off
between them. We desire the largest subset of all equivalent expressions
$E$ discovered such that in this subset, no expression dominates any other
expression, in terms of having both better area and better accuracy. This
subset is known as the Pareto frontier.  Figure~\ref{so:alg:pareto} shows
a simplified algorithm for calculating the Pareto frontier for a set of
equivalent expressions $\epsilon$.
\begin{figure}[ht]
    \centering
    \begin{algorithmic}
        \Function{Frontier}{$\epsilon$}
            \State{$\mathit{frontier} \gets \epsilon$}
            \For{$e \in \epsilon$}
                \For{$e^\prime \in \epsilon$}
                    \If{$\mathit{Area}(e^\prime) < \mathit{Area}(e)$ and
                        $\abserr(e^\prime) < \abserr(e)$}
                        \State{%
                            $\mathit{frontier} \gets
                                \mathit{frontier} / \{ e \}$}
                    \EndIf{}
                \EndFor{}
            \EndFor{}
            \State{\Return{$\mathit{frontier}$}}
        \EndFunction%
    \end{algorithmic}
    \caption{The Pareto frontier from a set of equivalent expressions.
    }\label{so:alg:pareto}
\end{figure} \\
Here, $\mathit{frontier} / \{ e \}$ is a set identical to $\mathit{frontier}$,
except that the element $e$ is removed.  We use the function $\abserr$ to
analyze the magnitudes of error bounds, which is defined as follows:
\begin{equation}
    \begin{aligned}
        \abserr(e) &= \max\left(
            \left| \mu^\sharp_{\min} \right|,
            \left| \mu^\sharp_{\max} \right|
        \right) \\
        & \quad \text{where~}
        \left(
            x^\sharp, \left[ \mu^\sharp_{\min}, \mu^\sharp_{\max} \right]
        \right) = \error(e)
    \end{aligned}
\end{equation}

\subsubsection{Equivalent Expressions Semantics}

Similar to the analysis of accuracy and resource usage, a set of equivalent
expressions can be computed with semantics. That is, we define structures,
\ie~sets of equivalent expressions, that can be manipulated with arithmetic
operators. In our equivalent expressions semantics, an element of
$\powersetof\exprset$ is used to assign a set of expressions to each node
in an expression parse tree. To begin with, at each leaf of the tree, the
variable or constant is assigned a set containing itself, as for $x$, the set
$\epsilon_x$ of equivalent expressions is $\epsilon_x = \{x\}$. After this, we
propagate the equivalence expressions in the parse tree's direction of flow,
using~\eqref{so:eq:equivalence_semantics} defined below:
\begin{equation}
    \begin{aligned}
        \epsilon_x \circ \epsilon_y &= \frontier\left(
            \eqstep^\star_k \left(
                E_\circ \left( \epsilon_x, \epsilon_y \right)
            \right) \right) \\
        & \text{where~}
        E_\circ(\epsilon_x, \epsilon_y) = \{
            e_x \circ e_y \mid e_x \in \epsilon_x \wedge e_y \in \epsilon_y
        \}, \\
        & \text{and~} \circ\in\{+, -, \times\}
    \end{aligned}
    \label{so:eq:equivalence_semantics}
\end{equation}
The equation implies that in the propagation procedure, it recursively
constructs a set of equivalent subexpressions for the parent node from
two child expressions, and uses the depth limited equivalence function
$\eqstep^\star_k$ to work out a larger set of equivalent expressions. To reduce
computation effort, we select only those expressions on the Pareto frontier
for the propagation in the DFG\@. Although in worst case the complexity of
this process is exponential, the selection by Pareto optimality accelerates
the algorithm significantly. For example, for the subexpression $a + b$ of our
sample expression:
\begin{equation}
    \begin{aligned}
        \epsilon_a + \epsilon_b
            &= \frontier\left(
                    \eqstep^\star_k \left(
                        E_\circ \left( \epsilon_a, \epsilon_b \right)
                    \right)
                \right) \\
            &= \frontier\left(
                    \eqstep^\star_k \left(
                        E_\circ \left( \{a\}, \{b\} \right)
                    \right)
                \right) \\
            &= \frontier\left(
                    \{ a + b, b + a \}
                \right)
    \end{aligned}
\end{equation}
Alternatively, we could view the semantics in terms of DFGs representing
the algorithm for finding equivalent expressions. The parsing of an
expression directly determines the structure of its DFG\@. For instance,
the expression $(a + b) \times (a + b)$ generates the DFG illustrated in
Figure~\ref{so:fig:tree_expr_flow}. The circles labeled $3$ and $7$ in this
diagram are shorthands for the operation $E_+$ and $E_\times$ respectively,
where $E_+$ and $E_\times$ is defined in~\eqref{so:eq:equivalence_semantics}.
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.6]{tree_expr_flow}
    \caption{The DFG for finding equivalent expressions of
    $(a + b) \times (a + b)$.}\label{so:fig:tree_expr_flow}
\end{figure}

For our example in Figure~\ref{so:fig:tree_expr_flow},
similar to the construction of data flow equations in
Section~\ref{bg:sec:abstract_interpretation} of Chapter~\ref{chp:background},
we can produce a set of equations from the data flow of the DFG, which now
produces equivalent expressions:
\begin{equation}
    \begin{aligned}
        \enter{1} &= \enter{1} \cup \{a\} &
        \enter{2} &= \enter{2} \cup \{b\} \\
        \enter{3} &= E_+(\enter{1}, \enter{2}) &
        \enter{4} &= \enter{3} \cup \enter{5} \\
        \enter{5} &= \eqstep_k(\enter{4}) &
        \enter{6} &= \frontier(\enter{5}) \\
        \enter{7} &= E_\times(\enter{6}, \enter{6}) &
        \enter{8} &= \enter{7} \cup \enter{9} \\
        \enter{9} &= \eqstep_k(\enter{8}) &
        \enter{10} &= \frontier(\enter{9})
    \end{aligned}
    \label{so:eq:tree_expr_flow}
\end{equation}
Because of loops in the DFG, it is no longer trivial to find the solution.
In general, the analysis equations are solved iteratively. We can
regard the set of equations as a single transfer function $F$ as in
\eqref{so:eq:transfer_function}, where the function $F$ takes as input
the variables $A(1), \ldots, A(10)$ appearing in the right-hand sides of
\eqref{so:eq:tree_expr_flow} and outputs the values $A(1), \ldots, A(10)$
appearing in the left-hand sides. Our aim is then to find an input $\vec{x}$ to
$F$ such that $F(\vec{x}) = \vec{x}$, \ie~a fixpoint of $F$.
\begin{equation}
      F((\enter{1}, \ldots, \enter{10}))
    = (\enter{1} \cup \{a\}, \ldots, \frontier(\enter{9}))
    \label{so:eq:transfer_function}
\end{equation}
Initially we assign $\enter{i} = \varnothing$ for $i\in\{1,2,\ldots,10\}$,
and we denote $\vec\varnothing = (\varnothing, \ldots, \varnothing)$.
Then we compute iteratively $F(\vec\varnothing)$, $F^2(\vec\varnothing) =
F(F(\vec\varnothing))$, and so forth, until the fixpoint solution $\fix F$ is
reached for some iteration $n$, that is:
\begin{equation}
    \fix F = F^n(\vec\varnothing) =
    F(F^n(\vec\varnothing)) = F^{n + 1}(\vec\varnothing)
\end{equation}
The fixpoint solution $\fix F$ gives a set of equivalent expressions derived
using our method, which is found at $\enter{10}$. In essence, the depth limit
acts as a sliding window.  The semantics allow hierarchical transformation of
subexpressions using a depth-limited search and the propagation of a set of
subexpressions that are locally Pareto optimal to the parent expressions in a
bottom-up hierarchy.

The problem with the semantics above is that the time complexity of
$\eqstep^\star_k$ scales poorly, since the worst case number of subexpressions
needed to explore increases exponentially with $k$. Therefore an alternative
method is to optimize it by changing the structure of the DFG slightly, as
shown in Figure~\ref{so:fig:tree_expr_flow_greedy}. The difference is that at
each iteration, the Pareto frontier filters the results to decrease the number
of expressions to process for the next iteration.
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.6]{tree_expr_flow_greedy}
    \caption{The alternative DFG for $(a + b) \times (a + b)$.
    }\label{so:fig:tree_expr_flow_greedy}
\end{figure}

In the rest of this chapter, we use \frontiertrace{} to indicate our equivalent
expression finding semantics, and \greedytrace{} to represent the alternative
method.
