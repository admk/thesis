\section{Program Syntax}

We define a simple programming language, ONEVAR, which allows only one variable
$\texttt{x}$ and the following sets:
\newcommand{\realset}{\ensuremath\mathbb{R}}
\newcommand{\opset}{\ensuremath\mathbf{OP}}
\begin{IEEEeqnarray*}{rClCl}
    n    &\in& \realset &\quad& \text{constants} \\
    op_a &\in& \opset_a &\quad& \opset_a = \{ +, -, * \} \\
    op_b &\in& \opset_b &\quad& \opset_b = \{ =, \neq, <, >, \leq, \geq \}
\end{IEEEeqnarray*}

ONEVAR has the following BNF style abstract syntax definition:
\newcommand{\baror}{\ensuremath ~ | ~}
\begin{IEEEeqnarray*}{rCl}
    a &::=& \texttt{x}
     \baror n
     \baror a_1 ~ op_a ~ a_2 \\
    b &::=& \texttt{true}
     \baror \texttt{false}
     \baror \texttt{not} ~ b
     \baror \texttt{x} ~ op_r ~ n \\
    S &::=& \texttt{x} := a
     \baror \texttt{skip}
     \baror S_1; S_2 \baror \\
    ~ & ~ & \texttt{if} ~ b ~ \texttt{then} ~ S_1 ~ \texttt{else} ~ S_2
     \baror \texttt{while} ~ b ~ \texttt{do} ~ S
\end{IEEEeqnarray*}

\section{Galois}

In fact, the abstract interpretation was employed in the above-mentioned
analysis, where it concerns only some certain property of the program, in this
case, a computable safe bound of the variable $\varx$.

The correctness of interval analysis in place of real analysis lies in the
following relation between each other:
\begin{equation}
    \begin{IEEEeqnarraybox}{rCll}
        \alpha(r) &=& \left[ \min(r), \max(r) \right]
             &\text{~for~} r \in \powersetof\realset \\
        \gamma(i) &=& \left\{ r \in \realset ~|~ r \in i \right\}
             &\text{~for~} i \in \intervalset \\
        &~& \text{and~}
            \alpha(r) \sqsubseteq i \text{~iff~} r \subseteq \gamma(i)
    \end{IEEEeqnarraybox}
\end{equation}

In abstract interpretation frameworks, the functions $\alpha:
\powersetof\realset \to \intervalset$ and $\gamma: \intervalset \to
\powersetof\realset$ are respectively the abstraction function and the
concretisation function. The relationship between $\powersetof\realset$ and
$\intervalset$ with these two functions is known as a Galois connection, often
written as follows:
\begin{equation}
    \lattice{\powersetof\realset}{\subseteq}
    \galois{\alpha}{\gamma}
    \lattice{\intervalset}{\sqsubseteq}
\end{equation}

Because of undecidability, the interval analysis may not terminate for
languages with loops, to overcome this one may resort to a finite lattice or
widening/narrowing operators~\cite{basic_absint}. In our method the expressions
are with no control flows and the analysis is guaranteed to terminate.

Let $\intervalset$ denote the set of intervals in the reals. It is clear that
$\intervalset$ is a complete lattice~\cite{nielson}, with the join and meet
rules in \eqref{eq:interval_operations}, as well as the partial order relation
in \eqref{eq:interval_order}. The complete lattice has the least element $\bot
= \varnothing$, as well as the greatest element $\top = \left[ -\infty, \infty
\right]$.
\begin{equation}
    \interval{a}{b} \sqsubseteq \interval{c}{d}
    \text{~iff~}
    a \geq c \wedge b \leq d
    \label{eq:interval_order}
\end{equation}

\section{FloPoCo}

For the area estimation of expressions, FloPoCo~\cite{flopoco} was used to
generate implementations of adders/subtracters and multipliers, then we used
Xilinx Synthesis Technology (XST)~\cite{xst} to estimate the number of LUTs
required in a Virtex-6 FPGA device (XC6VLX760) for these operators.


\section{Extensions}
\label{sub:extensions}

\subsection{Variation of Precisions}

We extend the Pareto frontier by allowing mantissa widths of expression
evaluation to vary. Initially, we compute equivalent expressions using the
methods outlined above, using single-precision floating point computations,
since we expect the Pareto frontier to be of similar shape under any mantissa
widths. Then each mantissa width ranging from 10 to 113 bits provides a context
in which derived expressions are evaluated for accuracy and area. Finally all
expressions with different mantissa widths are provided to form a single Pareto
frontier. In this process we calculate ranges of all intermediate variables
and results of the expressions, and use them to assign a minimum exponent
width necessary for the expressions. The widths are incorporated in the
estimation of area usage.


\section{Abstract Interpretation}

As an illustration, consider the following expression and its DFG in
Figure~\ref{bg:fig:sample_tree}\@:
\begin{equation}
    (a + b) \times (a + b)
    \label{bg:eq:absint_sample}
\end{equation}
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.6]{sample_tree}
    \caption{The DFG for the sample expression.}\label{bg:fig:sample_tree}
\end{figure}

We may wish to ask: if initially $a$ and $b$ are real numbers in the range of
$[0.2, 0.3]$ and $[2, 3]$ respectively, what would be the outcome of evaluating
this expression with real arithmetic? A straightforward approach is simulation.
Evaluating the expression for a large quantity of inputs will produce a set
of possible outputs of the expression. However the simulation approach is
unsafe, since there are infinite number of real-valued inputs possible and it
is infeasible to simulate for all.

A better method might be to represent the possible values of $a$ and $b$ using
ranges. To compute the ranges of its output values, we could operate on ranges
rather than values (note that the superscript $\sharp$ denotes ranges). Assume
that $a^\sharp_{init} = [0.2, 0.3]$, $b^\sharp_{init} = [2, 3]$, which are the
input ranges of $a$ and $b$, and $\enter{l}$ where $l \in \{1, 2, 3, 4\}$ are
the intervals of the outputs of the boxes labelled with $l$ in the DFG\@. We
extract the data flow from the DFG to produce the following set of equations:
\begin{equation}
    \begin{aligned}
        \enter{1} &= a^\sharp_{init} \\
        \enter{2} &= b^\sharp_{init} \\
        \enter{3} &= \enter{1} + \enter{2} \\
        \enter{4} &= \enter{3} \times \enter{3}
    \end{aligned}
    \label{bg:eq:absint_sample_analysis}
\end{equation}
For the equations above to make sense, addition and multiplication need to be
defined on intervals. We may define the following interval operations:
\begin{equation}
    \begin{aligned}
        \interval{a}{b} + \interval{c}{d} &= \interval{a + c}{b + d} \\
        \interval{a}{b} - \interval{c}{d} &=  \interval{a - d}{b - c} \\
        \interval{a}{b} \times \interval{c}{d} &=
            \interval{\min(s)}{\max(s)} \\
        \text{where~} s &= \{ a \times c, a \times d, b \times c, b \times d \}
    \end{aligned}
    \label{bg:eq:interval_operations}
\end{equation}
The solution to the set of~\eqref{bg:eq:absint_sample_analysis} for $\enter{4}$
is $[4.84, 10.89]$, which represents a safe bound on the output at the end
of program execution. Note that in actual execution of the program, the
semantics represent the values of intermediate variables, which are real
values. In our case, a set of real values forms the set of all possible
values produced by our code. However computing this set precisely is not,
in general, a possible task. Instead, we use abstract interpretation based
on intervals, which gives the abstract semantics of this program. Here, we
have achieved a classical interval analysis by \emph{defining} the meaning of
addition and multiplication on abstract mathematical structures (in this case
intervals) which capture a safe approximation of the original semantics of the
program.

Later in Sections~\ref{so:sec:resource}~and~\ref{so:sec:equivalent} of
Chapter~\ref{chp:stropt}, we further generalize the idea by defining the
meaning of these operations on more complex abstract structures which allow
us to scalably reason about the area of FPGA implementations and equivalent
program structures respectively.
