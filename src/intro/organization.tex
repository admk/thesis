\section{Thesis Organization}

Chapter~\ref{chp:background} serves to explain various essential concepts
used throughout this thesis.  Our techniques discussed in this thesis
naturally extends high-level synthesis (HLS), a process to compile a program
written in high-level languages such as C into circuits.  We therefore
start by introducing the advantages of HLS, compared against manual RTL
implementations.  We then present rigorous approaches from software static
analysis, specifically program semantics and abstract interpretation, to
bear on source-to-source transformation for HLS\@.  We introduce existing
intermediate representations designed for program optimizations, and highlight
the advantages and disadvantages of them relevant to our requirements.  We
draw comparisons between others' work and ours to better motivate the thesis's
contributions.  We further explain the existing program rewriting techniques
for numerical accuracy, which inspired our efficient discovery of equivalent
programs.  Finally, we introduce the concept of loop pipelining and how
restructuring numerical programs can optimize run time.

In Chapter~\ref{chp:stropt} we propose new methods to automatically optimize
the structure of arithmetic expressions for FPGA implementation as part of
a high-level synthesis flow.  It introduces the basis of the practice we
use to perform structural optimization on numerical programs, taking into
account axiomatic rules derived from real arithmetic, such as distributivity,
associativity and others.  A new efficient method is proposed to generate
a computable optimized subset of equivalent expressions from an original
expression.  Our approach explicitly target an optimized area/accuracy
trade-off, by automatically rewriting arithmetic expressions, and analyzing
each expression rewritten for its accuracy and area usage.  This gives
the synthesis tool the flexibility to choose an implementation satisfying
constraints on both accuracy and resource usage.  Using our technique to
optimize the structure of a variety of real world and artificially generated
examples in single-precision, we improve either their accuracy or the resource
utilization by up to 60\%.

Chapter~\ref{chp:progopt} presents a similar source-to-source optimization
targeting the trade-off between numerical accuracy and resource usage, but
we have extended it to optimize general numerical programs, consisting of
\iflit~statements and \whilelit~loops.  Because there are infinite number
of ways to rewrite numerical C programs, and many of these rewrites produce
programs that have the same resource usage, accuracy and latency properties,
we propose a novel expression-based intermediate representation called
metasemantic intermediate representation (MIR) to reduce the number of rewrites
to explore.  In Chapter~\ref{chp:progopt} we explain in detail the structure of
MIRs, and the back-and-forth translation between numerical C programs and MIRs.
We efficiently discover equivalent structures in MIRs by exploiting not only
the rules of real arithmetic, such as associativity and distributivity, but
also rules that enable control-flow restructuring.  Our numerical accuracy and
resource usage analyses are further extended to analyze MIRs.  Additionally, we
broaden the Pareto frontier in our optimization flow to automatically explore
the numerical implications of partial loop unrolling and loop splitting.  In
real applications, the tool discovers a wide range of Pareto optimal options,
and the most accurate one improves the accuracy of numerical programs by up to
65\%.

The optimization techniques we have discussed so far have only been limited
to minimizing area and round-off errors of numerical programs.  Often such
optimizations result in programs with longer run time, yet there are potentials
for these transformations to significantly reduce the run time of numerical
programs while improving resources and accuracy.  In Chapter~\ref{chp:latopt},
we therefore introduce a new analysis procedure to minimize yet another
objective: the total run time of the optimized program.  Together with
accuracy and resource utilization, these three form the simultaneous and
independent goals we use to produce the Pareto frontier.  In this chapter,
MIRs are extended with new operators to allow for arrays and matrices in the
source program, to optimize a wide-range of practical numerical applications.
Numerical programs typically spend most of their run time in loops, so
state-of-the-art high-level synthesis (HLS) tools use pipelining to schedule
them efficiently.  Still, the run time performance of the resultant FPGA
implementation is limited by data dependences between loop iterations.  We
thus present additional rewriting rules---memory access reductions---along
with arithmetic identities and control-flow transformations to alleviate some
of these dependence constraints.  HLS tools cannot safely enable such rewrites
by default because they may impact the accuracy of floating-point computations
and increase area usage, whereas we optimize run time while controlling the
implications on accuracy and area.  Again, the tool reports a multi-dimensional
Pareto frontier that the programmer can use to resolve the trade-off according
to their needs.  When applied to a suite of PolyBench and Livermore Loops
benchmarks, the tool has generated programs that enjoy up to a 12$\times$
speedup, with a simultaneous 7$\times$ increase in accuracy, at a cost of up to
4$\times$ more LUTs.

Finally, Chapter~\ref{chp:conclusion} concludes this thesis by summarizing
our research, and we discuss the potentials for how future research into
the structural optimization of numerical programs could further benefit the
high-level synthesis community.
